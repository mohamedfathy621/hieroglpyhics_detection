# -*- coding: utf-8 -*-
"""graduation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YQEdtfRZCXgPCYAU4QIAi81Km5Fs_M9o
"""

#image pre processing must be done to the image to apply sharpness filters and to remove the noise
#image pre filters may produce un consistent
import cv2
from PIL import Image
import numpy as np
from numpy.fft import fft2, ifft2
from skimage.util import random_noise
from skimage import color, data, restoration, feature
from skimage.filters import median, gaussian
from scipy.signal import convolve2d
#the original image is read first
image=cv2.imread('/content/sample_data/origin.jpg')
#first the image is turned into grayscale
img = color.rgb2gray(image)
#the image in convulted into a matrix using numpy library
psf = np.ones((5, 5)) / 25
img = convolve2d(img, psf, 'same')
#a standerd normal is produced for the image to be used by wiener filter
img += 0.1 * img.std() * np.random.standard_normal(img.shape)
#the image is then resoterd using this filters
#wiener filter , gaussian filter
out= restoration.wiener(img, psf, 1)
out=gaussian(out,sigma=0.4)
out=unsharp_mask(out, radius=20, amount=2)
##canny algorithm is used to determine idges
edg=feature.canny(out,sigma=2)
out= Image.fromarray(np.uint8(out * 255) , 'L')
edg= Image.fromarray(np.uint8(edg * 255) , 'L')
##you can use this snippet and the main code to see the diffrent outputs between the uses of filters
out.save("ftestm.jpg")
edg.save("edges.jpg")

from skimage import feature , color
from skimage.io import imread , imsave
from skimage.filters import unsharp_mask
from skimage import measure
import cv2
import numpy as np
from google.colab.patches import cv2_imshow

#this function is used to sort the signs occurding to thier orenitation
#wheter they are horinzontal or vertical
def pos (a,orination):
  sk=[]
  an=-1
  sorte=[]
  order=(orination=='vl')
  if(orination[0]=='v'):
    for i in range(0,len(a)-1):
      if(a[i+1][1]+5<a[i][1]+a[i][3]):
        if(an==-1):
          an=i
          sk=sk+[a[i]]
        sk=sk+[a[i+1]]
      elif(an>-1):
        sk=sorted(sk, key=lambda box: (box[0]),reverse=order)
        sorte=sorte+sk
        sk=[]
        an=-1
      else:
        sorte=sorte+[a[i]]
    if(an>-1):
        sorte=sorte+sorted(sk, key=lambda box: (box[0]),reverse=order)
    else:
        sorte=sorte+[a[-1]]
  return sorte

#this function is used to return a finetunned array segement lines used
#to cut the orignal image into sections
def rolo (a):
  #first an empty array is defined to hold the lines
    las=[]
    x=0
    #we start by loobing thorugh the original array
    for i in range(1,len(a)):
      #if the distance between the current line and the line before it passes
      #a certain threshhold the average of the distance of all the lines is
      #calcutaed to get the median distance which corrspondes to a the most
      # accurate line detection
        if(a[i]-a[i-1]>12):
            las=las+[sum(a[x:i])//(i-x)]
            x=i
    #one last calculation to make sure (~-~)
    las=las+[sum(a[x:len(a)])//(len(a)-x)]
    #check how the array look now
    print(las)
    #then an array is made to finetune the result
    re=[las[0]]
    avg=sum([las[i]-las[i-1] for i in range(1,len(las))])//(len(las)-1)
    print(avg)
    #we make this operation one more time using the average distance between
    #the lines to make sure that there are no dublicate lines
    for i in range(1,len(las)):
      if(las[i]-re[-1]>avg-5):
        re=re+[las[i]]
    #the result is returned to us
    return re
#this is the function which we use to finetune the sign detection result
#its only the first step and is used to remove impurites
def fntn (box):
    bou=box
    i=0
    #this process can be done in a recursive or an incermntal manner
    #i use to do it incremntal for the sake of optmization
    while(i<len(bou)):
      #firstly we start this operation with each box remaining in the array
      j=i+1
      #we loop thorugh each box in the array
      #keep in mind the boxes are sorted on postion
      while(j<len(bou)):
        #if certian conditions are met the box is removed from the array
        #this condition are used to check if the box is enclosed in a bigger box
        #using thier x,y postions
        if(bou[j][0]>=bou[i][0] and bou[j][1]>=bou[i][1] and bou[j][0]+bou[j][2]<=(bou[i][0]+bou[i][2]) and bou[j][1]+bou[j][3]<=(bou[i][1]+bou[i][3])):
          bou.pop(j)
        else:
          j=j+1
      i=i+1
    #after all enclosed boxes are removed we return the result to be finetuned again
    #in the second stage
    return bou

#this function is used to combine intersecting boxes toghther to get a box around
#the full sign such providing more accurace and reliveing more load of the
#classfication model back
def inter(box):
  bou=box
  i=0
  #this function is done in incremtnal manner as well
  while(i<len(bou)):
    j=i+1
    #first of all we start with a box and loop the boxes using it
    while(j<len(bou)):
      #we check thier x,y coo-ordinations to determine if they are intersecting
      if(((bou[j][0]<=bou[i][0] and (bou[j][0]+bou[j][2]>=bou[i][0]-1)) or (bou[i][0]<=bou[j][0] and bou[i][0]+bou[i][2]>=bou[j][0]-1) ) and bou[i][1]+bou[i][3]>=bou[j][1]+5 ):
        #then we combine thier coo-oridinations to make a bigger box
        xn=min(bou[i][0],bou[j][0])
        wn=max(bou[i][0]+bou[i][2],bou[j][0]+bou[j][2])-xn
        yn=min(bou[i][1],bou[j][1])
        hn=max(bou[i][1]+bou[i][3],bou[j][1]+bou[j][3])-yn
        bou[i]=[xn,yn,wn,hn]
        #the original box is then removed
        bou.pop(j)
        #then we use the bigger box to repeat this process
        if(i>0):i=i-1
        j=i+1
      elif(bou[j][1]+(bou[j][3]//2)>bou[i][1]+bou[i][3]):
        break
      else:
        j=j+1
    i=i+1
  return bou
#pre-process image
ori=  cv2.imread('/content/sample_data/fezo.jpg')
fino= cv2.imread('/content/sample_data/fezo.jpg')
fina= cv2.imread('/content/sample_data/fezo.jpg')
#first the main image is read into the script
img=imread('/content/sample_data/fezo.jpg')
#after that the image is turned into greyscale , and sharpen filter is used
#sharpen is used to detect edges with high percision
img=color.rgb2gray(img)
img=unsharp_mask(img, radius=20, amount=6)
edg=feature.canny(img,sigma=2.5)
#the result is then turned into unit format so i can be used in opencv libaries
edg=np.uint8(edg * 255)
#check the final result of edge detection for your self
imsave('/content/sample_data/result.jpg',edg)
#first hough line transform is used to detect sepration lines and orientation
lines = cv2.HoughLines(edg,1,np.pi/180,225)
#two arrays for horziontal and vertical are used to determine the orentation
res=[]
hor=[]
for line in lines:
   #first of all for each line detected in the image the angle between the line
   #and the origin of the image is detected so only horzointal and vertical lines
   #are saved
   rho,theta = line[0]
   a = np.cos(theta)
   b = np.sin(theta)
   x0 = a * rho
   y0 = b * rho
   x1 = int(x0 + 1000 * (-b))
   y1 = int(y0 + 1000 * (a))
   x2 = int(x0 - 1000 * (-b))
   y2 = int(y0 - 1000 * (a))
   #vertical lines are saved and drawn on the image as red lines
   if(theta==0):
    res=res+[x2]
    cv2.line(fino, (x1, y1), (x2, y2), (0, 0, 250), 2)
    #horziontal lines are detected and drawn on the image
   if(theta-1<0.6 and theta>1 and y1>0):
    hor=hor+[y1]
    cv2.line(fino, (x1, y1), (x2, y2), (0, 0, 250), 2)
#check the first result of hough transform for yourself
cv2.imwrite('/content/sample_data/fin.jpg', fino)
#lines are sorted occurdoing to thier postions and passed to the rolo function
#for further anlaysis
res.sort()
res=rolo(res)
#we then get a fine tuned result of lines for our image
print(res)
#then for each line in the result array we draw the lines on the image
for i in range(0,len(res)):
  b=np.sin(0)
  a=np.cos(0)
  x=res[i]
  y0 = b *x
  y1 = int(y0 + 1000 * (a))
  y2 = int(y0 - 1000 * (a))
  cv2.line(fina, (x, 0), (x , fina.shape[0]), (0, 0, 255), 2)
#check the fined tuned image for yourself
cv2.imwrite('/content/sample_data/fia.jpg', fina)
#then for each section in the image it passes through the sign detection process
for i in range(0,len(res)-1):
  #first of all a section is cut from the image with data from the lines array
  sec=ori[0:fina.shape[0],res[i]:res[i+1]]
  #check each section for yourself
  cv2.imwrite('/content/sample_data/sections/{}.jpg'.format(str(i)), sec)
  #we get the boundray and save it for later
  ow=res[i+1]
  #we then get the final image to be further procced
  sli=cv2.imread('/content/sample_data/sections/{}.jpg'.format(str(i)))
  gj=cv2.imread('/content/sample_data/sections/{}.jpg'.format(str(i)))
  #we turn it into gray scal and sharpen the image
  #the image is then thresholded using a variable which can be fixed or determined
  #automatically
  imgr = cv2.cvtColor(sli, cv2.COLOR_BGR2GRAY)
  imgr = cv2.GaussianBlur(imgr, (3, 3), 0)
  imgr=unsharp_mask(imgr, radius=3, amount=1)
  imgr = (255*imgr).astype(np.uint8)
  ret, thresh = cv2.threshold(imgr, 127, 255, 0)
  #check the result of thresholding for yourself
  cv2.imwrite('/content/sample_data/sections/thresh{}.jpg'.format(str(i)),thresh)
  #the contours in the image are fetched using cv2 libraries
  contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
  #an empty array is used to store the contores for each section
  boxes=[]
  for cnt in contours:
    #a bouding rectangle is drawn about each countor in green
    x,y,w,h=cv2.boundingRect(cnt)
    if(w<80 and h<500 and x<ow-10):boxes=boxes+[[x,y,w,h]]
    cv2.rectangle(sli, (x, y), (x + w, y + h), (0,255,0), 2)
  #see the first result before fine tuning for your self
  cv2.imwrite('/content/sample_data/sections/final{}.jpg'.format(str(i)),sli)
  #the boxes are then sorted from up to down
  boxes=sorted(boxes, key=lambda box: (box[2]*box[3]),reverse=True)
  #the boxes are sent to the fine tune function
  boxes=fntn(boxes)
  #the boxes are then sorted again to remove further conflitcions and impurties
  boxes=sorted(boxes, key=lambda box: (box[1]))
  boxes=inter(boxes)
  #then the boxes are further filterd based on size
  boxes=[box for box in boxes if(box[2]*box[3]>190)]
  #the final result is then finetuned to draw the final rectangels
  boxes=pos(boxes,'vl')
  for  box in boxes:
    x,y,w,h=box
    cv2.rectangle(gj, (x, y), (x + w, y+h), (0,255,0), 1)
  cv2.imwrite('/content/sample_data/sections/show{}.jpg'.format(str(i)),gj)
  #check the final result for your self
  #as the percison and accuracy of this script is not 100% but it achives high
  #enough accuracy to be further implemented into a deeplearning classfication model
  #which result can be passed to a further nlp model and a transaltion of whole
  #scripts of hierglyphics and be translated